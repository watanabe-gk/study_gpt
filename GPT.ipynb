{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/watanabe-gk/study_gpt/blob/main/GPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# モジュールのインストール"
      ],
      "metadata": {
        "id": "ZVoU47EWxhRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ライブラリーのインポート"
      ],
      "metadata": {
        "id": "wO7WwHdTGFrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title import\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "qz0qSOyBxox3"
      },
      "execution_count": 331,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "id": "-r5FkwUlS-TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14f1534e-c8e3-4575-894b-3e1a78bbef0f"
      },
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "位置の埋め込みレイヤー"
      ],
      "metadata": {
        "id": "Rofh1HStO6-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Position embedding\n",
        "class PositionEmbedding(nn.Module):\n",
        "  def __init__(self, context_size, d_model):\n",
        "    super(PositionEmbedding, self).__init__()\n",
        "    self.embedding = nn.Embedding(context_size, d_model)\n",
        "\n",
        "  def forward(self, x):\n",
        "    positions = torch.arange(0, x.size(1), device=x.device)\n",
        "    return self.embedding(positions)"
      ],
      "metadata": {
        "id": "xiPJvz5hO6qu"
      },
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "x = torch.LongTensor([[4545, 8410, 458, 3]])\n",
        "position_embedding = PositionEmbedding(4, 256)\n",
        "wpe = position_embedding(x)\n",
        "wpe"
      ],
      "metadata": {
        "id": "FeaA0-5OBc4H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43dbd8ab-d6e1-450d-9b8a-e3750bb28fda"
      },
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4800,  0.5192,  0.2423,  ..., -1.1535, -1.1035,  0.8625],\n",
              "        [ 0.4029,  1.0680, -1.3726,  ...,  2.1120, -2.4860,  0.0073],\n",
              "        [ 0.8543, -0.1828,  0.3025,  ...,  0.7086, -0.6651,  1.7564],\n",
              "        [-1.2328,  0.6328, -0.6807,  ...,  1.5711,  2.5385, -0.4173]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Transformerの論文で提案された正弦波バージョンを使用しました"
      ],
      "metadata": {
        "id": "Mv-sLG2701k5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Positional encoding\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, context_size, d_model):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(context_size, d_model)\n",
        "\n",
        "        for pos in range(context_size):\n",
        "            for i in range(0, d_model, 2):\n",
        "                pe[pos,i]   = math.sin(pos/(10000**((2*i)/d_model)))\n",
        "                pe[pos,i+1] = math.cos(pos/(10000**((2*i)/d_model)))\n",
        "\n",
        "        # 学習パラメーターの更新対象から外してクラス変数に確保(重要)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # positional encodingを埋め込みベクトルへ追加します\n",
        "        return self.pe[:, :x.size(1)].detach()"
      ],
      "metadata": {
        "id": "W85YnsQO3Hon"
      },
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise\n",
        "x = torch.LongTensor([[4545, 8410, 458, 3]])\n",
        "position_embedding = PositionEmbedding(4, 256)\n",
        "wpe = position_embedding(x)\n",
        "wpe"
      ],
      "metadata": {
        "id": "uKPZDjq6Ssyb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738cc97e-db67-42d8-9818-993736bff015"
      },
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.3726,  0.6929,  0.2467,  ..., -1.2644, -0.0486,  0.8893],\n",
              "        [-0.3559,  1.5074,  0.2217,  ..., -0.7366, -1.2823, -0.0582],\n",
              "        [-0.2904,  0.7499, -1.1993,  ...,  0.3225,  1.0186,  0.1519],\n",
              "        [ 1.0053, -0.8694,  0.0742,  ...,  0.1555,  1.6620, -0.4843]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Attention mask\n",
        "def create_attention_mask(context_size):\n",
        "    # 全ての要素が1となる正方行列を作成\n",
        "    mask = torch.ones((context_size, context_size))\n",
        "\n",
        "    # 対角線より下を0に変換\n",
        "    mask = torch.triu(mask, diagonal=1)\n",
        "\n",
        "    # True/False の型に変換(boolean)\n",
        "    mask = mask == 0\n",
        "\n",
        "    # 対角線より上の値を0、下の値を1に変換\n",
        "    mask = mask*1\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "9pGOSeYn1pYt"
      },
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: シーケンスが10の場合のマスクの作成\n",
        "create_attention_mask(10)"
      ],
      "metadata": {
        "id": "QHOVYS4Imukc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067959eb-4da1-4f62-df66-e3e335908029"
      },
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Scaled Dot-Product Attention\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    ''' Scaled Dot-Product Attention '''\n",
        "\n",
        "    def __init__(self, d_model, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.sqrt_d_k = d_model ** 0.5 # sqrt(d_k)　と同じ\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        score = torch.matmul(q, k.transpose(2, 3)) /  self.sqrt_d_k\n",
        "\n",
        "        if mask is not None:\n",
        "            score = score.masked_fill(mask == 0, float(\"-inf\"))\n",
        "\n",
        "        attn = F.softmax(score, dim=-1)\n",
        "        attn = self.dropout(attn)\n",
        "        output = torch.matmul(attn, v)\n",
        "\n",
        "        return output, attn"
      ],
      "metadata": {
        "id": "aOvsG1ozcoGg"
      },
      "execution_count": 339,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Square root\n",
        "print(math.sqrt(256))\n",
        "print(256 ** 0.5)"
      ],
      "metadata": {
        "id": "qZfGHmXSj0Yo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88eabf46-1a11-469b-afce-6abc930b21a2"
      },
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16.0\n",
            "16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Attention score\n",
        "context_size = 3\n",
        "dim = 4\n",
        "q = torch.randn(context_size, dim)\n",
        "k = torch.randn(context_size, dim)\n",
        "v = torch.randn(context_size, dim)\n",
        "print(q)\n",
        "print(k)\n",
        "print(v)\n",
        "\n",
        "a = q@k.T\n",
        "print(a)"
      ],
      "metadata": {
        "id": "ZVTsLKp0akNQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edcaebf7-71a3-40be-aca3-1d5b537be5c1"
      },
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1984,  0.5174, -1.8787, -1.7152],\n",
            "        [-1.4715, -0.3552,  0.2060,  0.3720],\n",
            "        [-0.3460,  1.6622,  0.7940, -0.8056]])\n",
            "tensor([[-0.6117, -0.0803,  1.1335,  0.3045],\n",
            "        [ 0.2897, -0.1205, -0.7841, -0.7923],\n",
            "        [ 1.6311, -0.9104, -2.0586,  0.5871]])\n",
            "tensor([[ 1.4550,  0.9173,  0.4871,  0.2666],\n",
            "        [-1.2774, -0.9786, -0.0969,  0.0608],\n",
            "        [ 0.4834, -1.8371,  0.8575,  1.5238]])\n",
            "tensor([[-2.5718,  2.7122,  2.0658],\n",
            "        [ 1.2754, -0.8398, -2.2824],\n",
            "        [ 0.7329, -0.2849, -4.1852]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Scaling\n",
        "a = a / (dim ** 0.5)\n",
        "print(a)"
      ],
      "metadata": {
        "id": "EUeKwq0jJr13",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26209f9d-5bd4-49b0-9a4d-894aec52ae8b"
      },
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2859,  1.3561,  1.0329],\n",
            "        [ 0.6377, -0.4199, -1.1412],\n",
            "        [ 0.3665, -0.1424, -2.0926]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Masking\n",
        "mask = create_attention_mask(context_size)\n",
        "print(a)\n",
        "print(mask)\n",
        "attn = a.masked_fill(mask == 0, float(\"-inf\"))"
      ],
      "metadata": {
        "id": "AqWU_o7VinX5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c137eff-f48c-4727-d2ae-bc2e3b58247d"
      },
      "execution_count": 343,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.2859,  1.3561,  1.0329],\n",
            "        [ 0.6377, -0.4199, -1.1412],\n",
            "        [ 0.3665, -0.1424, -2.0926]])\n",
            "tensor([[1, 0, 0],\n",
            "        [1, 1, 0],\n",
            "        [1, 1, 1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: probability\n",
        "F.softmax(attn, dim=1)"
      ],
      "metadata": {
        "id": "FKNOk5XCO82F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ca06ff-2b43-4688-88e0-2394ba5d877d"
      },
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.7422, 0.2578, 0.0000],\n",
              "        [0.5929, 0.3564, 0.0507]])"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-Head Attention"
      ],
      "metadata": {
        "id": "JcyGC6kg1qPt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$$\n",
        "\\text{MultiHead}(Q,K,V)=\\text{Concat}(head_1,…,head_h)W^O \\\\\n",
        "\\text{where } ℎead_i = \\text{Attention}(QW^{Q}_i, KW^{K}_i, VW^{V}_i).\n",
        "$$"
      ],
      "metadata": {
        "id": "qLdnuI8A6Wu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Multi-Head Attention\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    ''' Multi-Head Attention module '''\n",
        "\n",
        "    def __init__(self, n_head, d_model, dropout_rate=0.1):\n",
        "        super().__init__()\n",
        "        self.n_head = n_head\n",
        "        self.d_model = d_model\n",
        "        self.fc_q = nn.Linear(d_model, d_model)\n",
        "        self.fc_k = nn.Linear(d_model, d_model)\n",
        "        self.fc_v = nn.Linear(d_model, d_model)\n",
        "        self.attn = ScaledDotProductAttention(d_model, dropout_rate)\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        N = q.size(0) # バッチサイズ（Transformerの場合、QKVは同じサイズ）\n",
        "        S = q.size(1) # ウィンドウサイズ（Transformerの場合、QKVは同じサイズ）\n",
        "        H = self.n_head # マルチヘッドの数\n",
        "        D = self.d_model // self.n_head # 潜在区間の次元（Cross Attentonの場合、個別に定義）\n",
        "\n",
        "\n",
        "        # 線形変換\n",
        "        q = self.fc_q(q)\n",
        "        k = self.fc_k(k)\n",
        "        v = self.fc_v(v)\n",
        "\n",
        "        # 展開\n",
        "        q = q.view(N, S, H, D)\n",
        "        k = k.view(N, S, H, D)\n",
        "        v = v.view(N, S, H, D)\n",
        "\n",
        "        # Scaled dot-product attention\n",
        "        q, k, v = q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2)\n",
        "        x, attn = self.attn(q, k, v, mask=mask)\n",
        "\n",
        "        # Concat\n",
        "        # Transpose to move the head dimension back: b x lq x n x dv\n",
        "        # Combine the last two dimensions to concatenate all the heads together: b x lq x (n*dv)\n",
        "        # transposeは、見かけのテンソールを変形しているので、contiguous()で、メモリ内の形状を書き換えます。\n",
        "        x = x.transpose(1, 2).contiguous().view(N, S, -1) # re-assemble all head outputs side by side\n",
        "\n",
        "        # 線形変換\n",
        "        x = self.fc(x)\n",
        "\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        return x, attn"
      ],
      "metadata": {
        "id": "s7-h_jDn5xtg"
      },
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: transposeの使い方\n",
        "a = torch.randint(10,(128,15,8,256))\n",
        "print(a.shape)\n",
        "a.transpose(1,2).shape"
      ],
      "metadata": {
        "id": "rgo2ZEOtzjOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f956f68-9ef8-4eed-ed90-fbec2711ea5f"
      },
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 15, 8, 256])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 8, 15, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: Multi-head attention\n",
        "n_head = 8\n",
        "d_model = 16\n",
        "attention = MultiHeadAttention(n_head, d_model)"
      ],
      "metadata": {
        "id": "U5gIUcDEg4Ed"
      },
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "context_size = 10\n",
        "# Query: x\n",
        "# Attentionブロックへの最初の入力となるクエリxを作成します\n",
        "x = torch.randn(batch_size, context_size, d_model)\n",
        "q, w = attention(x, x, x)"
      ],
      "metadata": {
        "id": "j0pq4rImnbmf"
      },
      "execution_count": 348,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q.shape # 入力トークン数分の潜在変数"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_pNJ6WyMhOC",
        "outputId": "c0bab807-fc44-419d-e874-d70f3442dead"
      },
      "execution_count": 349,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 349
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w.shape  # 入力トークン数の正方行列"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x-SCMl4Mh58",
        "outputId": "d0322efb-3d1d-4504-e9fa-8d64a66c87c8"
      },
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 8, 10, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Position-wise feed forward Networks"
      ],
      "metadata": {
        "id": "Gz-RpjA8WAkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "論文 '$\\text{Attention Is All You Need}$' では、FeedForwardは、ReLU活性化関数を介した2つの線形変換で構成されています。\n",
        "\n",
        "$$\n",
        "\\text{FFN}(x) = \\text{max}(0, xW_1 + b_1)W_2 + b_2  \n",
        "\\\\\n",
        "$$\n",
        "\n",
        "入力と出力の次元は$d_{model} = 512$で、隠れ層の次元は$d_{ff} = 2048$です。"
      ],
      "metadata": {
        "id": "Cj7yKOLDV_Oa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Feed Forward\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, dropout_rate=0.1):\n",
        "        super(FeedForward, self).__init__()\n",
        "        # 潜在空間の４倍の隠れ層を持つMLPを作成\n",
        "        self.fc1 = nn.Linear(d_model, d_model * 4)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.fc2 = nn.Linear(d_model * 4, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.fc1(x)\n",
        "        h = F.gelu(h)\n",
        "        h = self.fc2(h)\n",
        "        h = self.dropout(h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "tW3puAtb0n81"
      },
      "execution_count": 351,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ko27Wl9FOjRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: FeedForward\n",
        "d_model = 2\n",
        "ff = FeedForward(d_model)\n",
        "print(ff)\n",
        "x = torch.randn(d_model)\n",
        "print(x)\n",
        "ff(x)"
      ],
      "metadata": {
        "id": "rJ7aagj8tiDI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd78ccf0-12db-4eaa-d940-895f66dfb318"
      },
      "execution_count": 352,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FeedForward(\n",
            "  (fc1): Linear(in_features=2, out_features=8, bias=True)\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=8, out_features=2, bias=True)\n",
            ")\n",
            "tensor([-1.5701, -0.4246])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0000, -0.2646], grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 352
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Transformer Block\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, d_model, n_head, dropout_rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.norm_1 = nn.LayerNorm(d_model)\n",
        "        self.norm_2 = nn.LayerNorm(d_model)\n",
        "        self.attn = MultiHeadAttention(n_head, d_model, dropout_rate)\n",
        "        self.ff = FeedForward(d_model)\n",
        "\n",
        "        nn.init.normal_(self.norm_1.weight, mean=0, std=0.02)\n",
        "        nn.init.normal_(self.norm_2.weight, mean=0, std=0.02)\n",
        "\n",
        "    # GPT-1\n",
        "    def forward(self, x, mask=None):\n",
        "        rx = x # 残差 (residual value)\n",
        "        x, w = self.attn(x, x, x, mask)\n",
        "        x = self.norm_1(x + rx)\n",
        "\n",
        "        rx = x\n",
        "        x = self.ff(x)\n",
        "        x = self.norm_2(x + rx)\n",
        "\n",
        "        return x, w"
      ],
      "metadata": {
        "id": "BfRk6VXK0OkS"
      },
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise: TransformerBlock\n",
        "d_model = 2\n",
        "n_head = 1\n",
        "block = TransformerBlock(d_model, n_head)\n",
        "batch_size = 1\n",
        "context_size = 5\n",
        "# token vectors\n",
        "x = torch.randn(batch_size, context_size, d_model)\n",
        "y, w = block(x)\n",
        "print(x)\n",
        "print(y.shape)\n",
        "print(y)\n",
        "print(w.shape)\n",
        "print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSBWWHSA0R79",
        "outputId": "6fbab289-8e5a-4fd6-9840-3cacf80554fd"
      },
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 0.6843, -0.5601],\n",
            "         [ 1.4043,  0.4406],\n",
            "         [ 1.4172,  0.4066],\n",
            "         [ 0.5804,  0.8283],\n",
            "         [-1.0066, -0.1304]]])\n",
            "torch.Size([1, 5, 2])\n",
            "tensor([[[-0.0450, -0.0142],\n",
            "         [-0.0450, -0.0142],\n",
            "         [-0.0450, -0.0142],\n",
            "         [-0.0451, -0.0142],\n",
            "         [-0.0451, -0.0142]]], grad_fn=<NativeLayerNormBackward0>)\n",
            "torch.Size([1, 1, 5, 5])\n",
            "tensor([[[[0.1215, 0.1525, 0.1484, 0.2998, 0.3889],\n",
            "          [0.1244, 0.1816, 0.1768, 0.3182, 0.3101],\n",
            "          [0.0000, 0.1802, 0.0000, 0.3197, 0.3130],\n",
            "          [0.1727, 0.2033, 0.2007, 0.2657, 0.2686],\n",
            "          [0.2199, 0.1790, 0.1787, 0.2135, 0.3200]]]], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title GPT\n",
        "class GPT(nn.Module):\n",
        "    def __init__(self, vocab_size, context_size, d_model, n_block, n_head, dropout_rate=0.1):\n",
        "        super(GPT, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.context_size = context_size\n",
        "        self.d_model = d_model\n",
        "        self.n_block = n_block\n",
        "        self.n_head = n_head\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        # self.position_embedding = PositionEmbedding(context_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(context_size, d_model)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.transformer_blocks = nn.ModuleList(\n",
        "            [TransformerBlock(d_model, n_head, dropout_rate) for _ in range(self.n_block)])\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.fc = nn.Linear(d_model * context_size, vocab_size)\n",
        "\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "        nn.init.normal_(self.token_embedding.weight, mean=0.0, std=0.02)\n",
        "        # nn.init.normal_(self.position_embedding.embedding.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        x = self.token_embedding(x) + self.positional_encoding(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for block in self.transformer_blocks:\n",
        "            x, w = block(x, mask)\n",
        "\n",
        "        # GPT-2\n",
        "        x = self.norm(x)\n",
        "\n",
        "        x = x.view(-1, self.context_size * self.d_model)\n",
        "\n",
        "        # 線形変換\n",
        "        x = self.fc(x)\n",
        "\n",
        "        # Softmax は損失関数に組み込まれています。\n",
        "\n",
        "        return x, w"
      ],
      "metadata": {
        "id": "1H3MZSp4m3A7"
      },
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの動作を確認しましょう\n",
        "context_size = 5 # @param{type:'integer'}\n",
        "vocab_size = 10   # @param{type:'integer'}\n",
        "d_model = 8 # @param{type:'integer'}\n",
        "n_block = 6 # @param{type:'integer'}\n",
        "n_head = 4 # @param{type:'integer'}"
      ],
      "metadata": {
        "id": "Wo8vzm01zSWX"
      },
      "execution_count": 356,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの動作を確認しましょう\n",
        "model = GPT(vocab_size, context_size, d_model, n_block, n_head)\n",
        "mask = create_attention_mask(context_size).to(device)\n",
        "x = torch.LongTensor([[1,2,3,4,9]]) # 0～9までの数値を使って context_size の長さの配列を作成します。\n",
        "y, w = model(x)"
      ],
      "metadata": {
        "id": "9Y6YSvVdxDD-"
      },
      "execution_count": 357,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "653tDmDa2E1B",
        "outputId": "1e3add0b-7b8d-4a59-9add-ac5bab7c7086"
      },
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 358
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7L7dXnu2GF_",
        "outputId": "b27a1b3e-f0fc-4de3-f416-f9dbb3cc8efa"
      },
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.4637, -0.0513, -0.1753,  1.7514, -0.1457,  0.3194,  1.4937,  1.5145,\n",
              "          1.7834, -1.4435]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 359
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.argmax() # [2,3,4,9,8]になる"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttkR-aNc2OWa",
        "outputId": "5462d68b-47ba-44ae-be8a-8b010c82d0fd"
      },
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(8)"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C4ok1jF-24zj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}